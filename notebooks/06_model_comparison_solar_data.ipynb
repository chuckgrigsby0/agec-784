{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67fea486",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "\n",
    "In this notebook, we compare the predictive accuracy of K-Nearest Neighbors, Decision Trees, Linear Regression (Linear Probability Model for classification), and Logistic Regression for both classification and regression tasks using the solar installation dataset.\n",
    "\n",
    "Click the badge below to open in Google Colab:\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/chuckgrigsby0/agec-784/blob/main/notebooks/06_model_comparison_solar_data.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3a1b5d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8379a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9c5a42",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a8c761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL for raw GitHub content\n",
    "base_url = \"https://raw.githubusercontent.com/chuckgrigsby0/agec-784/main/data/\"\n",
    "\n",
    "# Load solar directly from GitHub URL\n",
    "solar_data = pd.read_csv(base_url + 'solar-data.csv')\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"Number of rows and columns: {solar_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7d5f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the data\n",
    "solar_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c2b8e3",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b4d7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary numeric variable for classification models\n",
    "# Classification models require numeric (0/1) rather than categorical (Yes/No) target variables\n",
    "i = solar_data.columns.get_loc('Install?') + 1\n",
    "solar_data.insert(i, 'Install', np.where(solar_data['Install?'] == 'Yes', 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c897454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training (70%) and testing (30%) sets\n",
    "# We evaluate model performance using test data to assess predictive accuracy on unseen data\n",
    "# random_state ensures reproducibility\n",
    "train_data, test_data = train_test_split(\n",
    "    solar_data,\n",
    "    train_size=0.7,\n",
    "    test_size=0.3,\n",
    "    random_state=731\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5f8d4a",
   "metadata": {},
   "source": [
    "## Classification Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b3c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_classification_models(train_data, test_data, knn_nn, tree_min_samples_split, tree_min_samples_leaf):\n",
    "    \"\"\"\n",
    "    Compare classification accuracy across multiple models.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    train_data : DataFrame\n",
    "        Training dataset\n",
    "    test_data : DataFrame\n",
    "        Testing dataset\n",
    "    knn_nn : int, optional\n",
    "        Number of neighbors for KNN\n",
    "    tree_min_samples_split : int, optional\n",
    "        Minimum samples required to split a node in Decision Tree\n",
    "    tree_min_samples_leaf : int, optional\n",
    "        Minimum samples required in a leaf node in Decision Tree\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with Model names and their Accuracy scores\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X_train = train_data[['Income', 'PSH']]\n",
    "    y_train = train_data['Install']\n",
    "    X_test = test_data[['Income', 'PSH']]\n",
    "    y_test = test_data['Install']\n",
    "    \n",
    "    # 1. KNN Classification (k=3)\n",
    "    # KNN requires feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=knn_nn, metric='euclidean')\n",
    "    knn_clf.fit(X_train_scaled, y_train)\n",
    "    knn_preds = knn_clf.predict(X_test_scaled)\n",
    "    knn_accuracy = accuracy_score(y_test, knn_preds)\n",
    "    results.append({'Model': f'KNN (k={knn_nn})', 'Accuracy': knn_accuracy})\n",
    "    \n",
    "    # 2. Decision Tree Classification\n",
    "    tree_clf = DecisionTreeClassifier(\n",
    "        criterion='gini',              # Measure of split quality for classification\n",
    "        min_samples_split=tree_min_samples_split,           # Minimum samples required to split a node\n",
    "        min_samples_leaf=tree_min_samples_leaf,            # Minimum samples required in a leaf node\n",
    "        random_state=731               # For reproducibility\n",
    "    )\n",
    "    tree_clf.fit(X_train, y_train)\n",
    "    tree_preds = tree_clf.predict(X_test)\n",
    "    tree_accuracy = accuracy_score(y_test, tree_preds)\n",
    "    results.append({'Model': 'Decision Tree', 'Accuracy': tree_accuracy})\n",
    "    \n",
    "    # 3. Linear Probability Model (LPM)\n",
    "    lpm_train = smf.ols(formula='Install ~ Income + PSH', data=train_data).fit()\n",
    "    lpm_pred_probs = lpm_train.predict(test_data)\n",
    "    lpm_preds = np.where(lpm_pred_probs >= 0.5, 1, 0)\n",
    "    lpm_accuracy = accuracy_score(test_data['Install'], lpm_preds)\n",
    "    results.append({'Model': 'Linear Probability Model', 'Accuracy': lpm_accuracy})\n",
    "    \n",
    "    # 4. Logistic Regression\n",
    "    logit_train = smf.logit(formula='Install ~ Income + PSH', data=train_data).fit()\n",
    "    logit_pred_probs = logit_train.predict(test_data)\n",
    "    logit_preds = np.where(logit_pred_probs >= 0.5, 1, 0)\n",
    "    logit_accuracy = accuracy_score(test_data['Install'], logit_preds)\n",
    "    results.append({'Model': 'Logistic Regression', 'Accuracy': logit_accuracy})\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values('Accuracy', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare classification models\n",
    "classification_results = compare_classification_models(train_data, test_data, knn_nn=3, tree_min_samples_split=5, tree_min_samples_leaf=3)\n",
    "print(\"Classification Model Comparison\")\n",
    "print(\"=\"*40)\n",
    "classification_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d8e1f2",
   "metadata": {},
   "source": [
    "## Regression Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g3h4i5j6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_regression_models(train_data, test_data, knn_nn, tree_min_samples_split, tree_min_samples_leaf):\n",
    "    \"\"\"\n",
    "    Compare regression performance across multiple models.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    train_data : DataFrame\n",
    "        Training dataset\n",
    "    test_data : DataFrame\n",
    "        Testing dataset\n",
    "    knn_nn : int, optional\n",
    "        Number of neighbors for KNN\n",
    "    tree_min_samples_split : int, optional\n",
    "        Minimum samples required to split a node in Decision Tree\n",
    "    tree_min_samples_leaf : int, optional\n",
    "        Minimum samples required in a leaf node in Decision Tree\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with Model names, MSE, and R² scores\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X_train = train_data[['Income', 'PSH']]\n",
    "    y_train = train_data['Profit']\n",
    "    X_test = test_data[['Income', 'PSH']]\n",
    "    y_test = test_data['Profit']\n",
    "    \n",
    "    # 1. KNN Regression (k=3)\n",
    "    # KNN requires feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    knn_reg = KNeighborsRegressor(n_neighbors=knn_nn, metric='euclidean')\n",
    "    knn_reg.fit(X_train_scaled, y_train)\n",
    "    knn_preds = knn_reg.predict(X_test_scaled)\n",
    "    knn_mse = mean_squared_error(y_test, knn_preds)\n",
    "    knn_r2 = r2_score(y_test, knn_preds)\n",
    "    results.append({'Model': f'KNN (k={knn_nn})', 'MSE': knn_mse, 'R²': knn_r2})\n",
    "    \n",
    "    # 2. Decision Tree Regression\n",
    "    tree_reg = DecisionTreeRegressor(\n",
    "        criterion='squared_error',     # MSE criterion for regression\n",
    "        min_samples_split=tree_min_samples_split,           # Minimum samples required to split a node\n",
    "        min_samples_leaf=tree_min_samples_leaf,            # Minimum samples required in a leaf node\n",
    "        random_state=731               # For reproducibility\n",
    "    )\n",
    "    tree_reg.fit(X_train, y_train)\n",
    "    tree_preds = tree_reg.predict(X_test)\n",
    "    tree_mse = mean_squared_error(y_test, tree_preds)\n",
    "    tree_r2 = r2_score(y_test, tree_preds)\n",
    "    results.append({'Model': 'Decision Tree', 'MSE': tree_mse, 'R²': tree_r2})\n",
    "    \n",
    "    # 3. Linear Regression (OLS)\n",
    "    ols_train = smf.ols(formula='Profit ~ Income + PSH', data=train_data).fit()\n",
    "    ols_preds = ols_train.predict(test_data)\n",
    "    ols_mse = mean_squared_error(test_data['Profit'], ols_preds)\n",
    "    ols_r2 = r2_score(test_data['Profit'], ols_preds)\n",
    "    results.append({'Model': 'Linear Regression (OLS)', 'MSE': ols_mse, 'R²': ols_r2})\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values('R²', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k7l8m9n0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare regression models\n",
    "regression_results = compare_regression_models(train_data, test_data, knn_nn=3, tree_min_samples_split=5, tree_min_samples_leaf=3)\n",
    "print(\"Regression Model Comparison\")\n",
    "print(\"=\"*40)\n",
    "regression_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agec-784",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
