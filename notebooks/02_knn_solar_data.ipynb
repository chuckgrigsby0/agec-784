{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a723edc",
   "metadata": {},
   "source": [
    "### Load packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93abc377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b2761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL for raw GitHub content\n",
    "base_url = \"https://raw.githubusercontent.com/chuckgrigsby0/agec-784/main/data/\"\n",
    "\n",
    "# Load solar directly from GitHub URL\n",
    "solar_data = pd.read_csv(base_url + 'solar-data.csv')\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"Number of rows and columns: {solar_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d893571c",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9200ae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the column names\n",
    "# Note that .columns is an attribute of solar_data\n",
    "print(solar_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8171152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first 5 rows of the dataset\n",
    "print(solar_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c4b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute summary statistics, rounded to 4 decimal places \n",
    "# Note: only numeric columns are included\n",
    "np.round(solar_data.describe(), decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c373c6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get counts of number of households that installed solar or not, we can use the value_counts() method\n",
    "solar_data['Install?'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0293165a",
   "metadata": {},
   "source": [
    "We can create a correlation matrix using the `corr()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d0865",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_mat = solar_data.select_dtypes(include=np.number).corr()\n",
    "\n",
    "np.round(cor_mat, decimals=4) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c51ddb",
   "metadata": {},
   "source": [
    "### Create a binary outcome variable for `Install?` (Yes = 1, No = 0)\n",
    "\n",
    "To prepare the data for estimation, we create a binary (0/1) variable based on solar installation status. The `insert()` method allows us to place `Install` immediately following `Install?`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d8ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i = solar_data.columns.get_loc('Install?') + 1\n",
    "solar_data.insert(i, 'Install', np.where(solar_data['Install?'] == 'Yes', 1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f79c035",
   "metadata": {},
   "source": [
    "### Estimate a KNN Model with Unscaled Data\n",
    "\n",
    "The KNN classifier is sensitive to the scale of variables, as predictions are based on distances between observations' features. Variables with larger scales will dominate the distance calculation. For example, if one variable ranges from 33-290 (`Income` in thousands of dollars) while another ranges from 1.5-7 (peak-sun-hours, `PSH`), `Income` will disproportionately influence which neighbors are considered \"nearest,\" even if `PSH` is equally important for classification. Therefore, we should standardize predictors to ensure equal contribution to distances. One common approach is Z-score standardization, which transforms all variables to have mean zero and standard deviation one: $z = \\frac{x - \\bar{x}}{\\text{sd}(x)}$\n",
    "\n",
    "We will compare unscaled and scaled model accuracy at the end of the notebook. First, we estimate a KNN model using the scaled data. \n",
    "\n",
    "We will use `Income` and `PSH` as predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60064894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = (StandardScaler(with_mean=True, with_std=True) # Implies mean of 0 and SD of 1\n",
    "        .set_output(transform='pandas')\n",
    ")\n",
    "predictor_vars_scaled = scaler.fit_transform(solar_data[['Income', 'PSH']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18cdb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    predictor_vars_scaled,\n",
    "    solar_data['Install'],\n",
    "    train_size=0.6,\n",
    "    test_size=0.4,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d2db90",
   "metadata": {},
   "source": [
    "#### Evaluating on Training vs Test Data\n",
    "\n",
    "Unlike parametric models, KNN does not learn parameters during fitting. The `fit()` call stores the training data in memory. When predicting, KNN computes distances from each test observation to all training observations, identifies the k-nearest neighbors, and uses majority vote for classification. With `n_neighbors=1`, evaluating on training data yields perfect accuracy since each point is its own nearest neighbor. However, evaluating on test data provides a reliable estimate of generalization error, as predictions use only the stored training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a2e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using one nearest neighbor and Euclidean distance\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "knn_fit = knn.fit(X_train, y_train)\n",
    "\n",
    "# Evaluating on Training Data\n",
    "print(knn_fit.score(X_train, y_train))\n",
    "\n",
    "# Evaluating on Test Data\n",
    "print(knn_fit.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f800ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using three nearest neighbors and Euclidean distance\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_fit = knn.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Evaluating on Training Data\n",
    "print(knn_fit.score(X_train, y_train))\n",
    "\n",
    "# Evaluating on Test Data\n",
    "print(knn_fit.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4cfd53",
   "metadata": {},
   "source": [
    "### We can obtain the predicted outcomes using the `predict()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dfb8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating on Test Data\n",
    "preds = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': knn_fit.predict(X_test)\n",
    "})\n",
    "\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e20cf8f",
   "metadata": {},
   "source": [
    "### Assessing Model Accuracy\n",
    "\n",
    "#### Accuracy = 1 - Misclassification Rate\n",
    "\n",
    "The `score()` method measures the model's predictive accuracy. We can also compute accuracy manually comparing actual and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccba04d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All yield the same result\n",
    "\n",
    "print(np.mean(1 - preds['Actual'] != preds['Predicted'])) # Manual calculation of accuracy\n",
    "\n",
    "print(np.mean(preds['Actual'] == preds['Predicted'])) # Manual calculation of accuracy\n",
    "\n",
    "print(knn_fit.score(X_test, y_test)) # Using score() method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d51f5b",
   "metadata": {},
   "source": [
    "#### Confusion Matrix\n",
    "\n",
    "A confusion matrix displays the model's predictions versus actual outcomes: true negatives (TN, correctly predicting non-installation), false negatives (FN, incorrectly predicting non-installation), true positives (TP, correctly predicting installation), and false positives (FP, incorrectly predicting installation). The diagonal elements represent correct predictions, while off-diagonal elements represent errors. The model correctly predicted 13 non-installations (TN) and 20 installations (TP), but incorrectly predicted 4 households would not install when they did (FN) and 3 would install when they did not (FP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e282f06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(preds['Actual'], preds['Predicted'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88abee06",
   "metadata": {},
   "source": [
    "#### Decision Boundary\n",
    "\n",
    "The decision boundary plot shows the regions where the KNN model predicts each class across the two features (`Income` and `PSH`). The colored background regions represent what the model would predict for any hypothetical point in that area, based on the majority vote of the k=3 nearest training neighbors. Test data points are overlaid as scatter points, allowing us to assess model performance. Points falling in the correctly colored region indicate correct predictions, while points in the wrong region indicate misclassifications. As k increases, the decision boundaries become smoother and less sensitive to individual training points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35e50e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "# Create a KNN classifier with k=5 neighbors using Euclidean distance\n",
    "knn = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "\n",
    "# Fit the model on training data (stores X_train and y_train in memory)\n",
    "knn_fit = knn.fit(X_train, y_train)\n",
    "\n",
    "# Create the decision boundary visualization\n",
    "disp = DecisionBoundaryDisplay.from_estimator(\n",
    "    estimator=knn_fit,              # The fitted KNN model\n",
    "    X=X_train,                      # Training data used to determine plot range and boundary\n",
    "    plot_method='contourf',         # Use filled contours for the background regions\n",
    "    response_method='predict',      # Use the predict method to determine class regions\n",
    "    xlabel=X_train.columns[0],      # Label x-axis with first feature name (Income)\n",
    "    ylabel=X_train.columns[1],      # Label y-axis with second feature name (PSH)\n",
    "    alpha=0.5,                      # Set transparency of colored regions to 50%\n",
    "    cmap='RdYlBu_r',               # Color scheme: reversed red-yellow-blue\n",
    ")\n",
    "\n",
    "# Overlay test data points on the decision boundary plot\n",
    "# c=y_test colors points by their actual class labels\n",
    "scatter = disp.ax_.scatter(\n",
    "    X_test[\"Income\"],               # X-coordinates from test data\n",
    "    X_test[\"PSH\"],                  # Y-coordinates from test data\n",
    "    c=y_test,                       # Color by actual test labels\n",
    "    cmap='Paired',                  # Colormap for the scatter points\n",
    "    s=20,                           # Size of points\n",
    "    edgecolor=\"b\"                   # Blue edge around each point\n",
    ")\n",
    "\n",
    "# Set x-axis limits to match the range of test data\n",
    "disp.ax_.set_xlim(X_test[\"Income\"].min(), X_test[\"Income\"].max())\n",
    "\n",
    "# Set y-axis limits to match the range of test data\n",
    "disp.ax_.set_ylim(X_test[\"PSH\"].min(), X_test[\"PSH\"].max())\n",
    "\n",
    "# Add legend to identify the classes\n",
    "disp.ax_.legend(\n",
    "    scatter.legend_elements()[0],   # Get the legend handles from scatter plot\n",
    "    ['No', 'Yes'],                  # Label the classes\n",
    "    loc='best',                     # Automatically choose best legend location\n",
    "    title='Classes'                 # Title for the legend\n",
    ")\n",
    "\n",
    "# Add title to the plot showing the algorithm and k value\n",
    "# The underscore (_) captures the return value (not needed)\n",
    "_ = disp.ax_.set_title(\n",
    "    f\"Solar Installation Classification\\nKNN (k={knn.n_neighbors}) Decision Boundary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58de21b7",
   "metadata": {},
   "source": [
    "### Compare scaled and unscaled model accuracy\n",
    "\n",
    "We will compare model accuracy using  the scaled and unscaled predictors and plot the decision boundary plots to visualize model performance. \n",
    "\n",
    "First, we will prepare the unscaled train and test splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b406b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_vars = solar_data.loc[:, ['Income', 'PSH']]\n",
    "\n",
    "X_train_unscaled, X_test_unscaled, y_train_unscaled, y_test_unscaled = train_test_split(\n",
    "    predictor_vars,\n",
    "    solar_data['Install'],\n",
    "    train_size=0.6,\n",
    "    test_size=0.4,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e8a66f",
   "metadata": {},
   "source": [
    "We repeat the same steps to create decision boundary figures for both the unscaled and scaled models, but now plot them side-by-side for comparison. The key is using `plt.subplots(1, 2)` to create one figure with two subplot axes, then specifying which axes to draw on using the `ax` parameter in `DecisionBoundaryDisplay.from_estimator()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156c45b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Unscaled model results\n",
    "knn_unscaled = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_unscaled.fit(X_train_unscaled, y_train_unscaled)\n",
    "\n",
    "# Create decision boundary on left subplot\n",
    "disp1 = DecisionBoundaryDisplay.from_estimator(\n",
    "    estimator=knn_unscaled,\n",
    "    X=X_train_unscaled,\n",
    "    ax=ax1,                         # Specify which subplot to use\n",
    "    plot_method='contourf',\n",
    "    response_method='predict',\n",
    "    xlabel=X_train_unscaled.columns[0],\n",
    "    ylabel=X_train_unscaled.columns[1],\n",
    "    alpha=0.5,\n",
    "    cmap='RdYlBu_r'\n",
    ")\n",
    "\n",
    "# Add scatter points\n",
    "scatter1 = ax1.scatter(\n",
    "    X_test_unscaled[\"Income\"],\n",
    "    X_test_unscaled[\"PSH\"],\n",
    "    c=y_test_unscaled,\n",
    "    cmap='Paired',\n",
    "    s=20,\n",
    "    edgecolor=\"b\"\n",
    ")\n",
    "\n",
    "# Customize left plot\n",
    "ax1.set_xlim(X_test_unscaled[\"Income\"].min(), X_test_unscaled[\"Income\"].max())\n",
    "ax1.set_ylim(X_test_unscaled[\"PSH\"].min(), X_test_unscaled[\"PSH\"].max())\n",
    "ax1.legend(scatter1.legend_elements()[0], ['No', 'Yes'], loc='best', title='Classes')\n",
    "acc_unscaled = knn_unscaled.score(X_test_unscaled, y_test_unscaled)\n",
    "ax1.set_title(f\"Without Scaling\\nKNN (k=3) | Accuracy: {acc_unscaled:.3f}\")\n",
    "\n",
    "# Scaled model results\n",
    "knn_scaled = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_scaled.fit(X_train, y_train)\n",
    "\n",
    "# Create decision boundary on right subplot\n",
    "disp2 = DecisionBoundaryDisplay.from_estimator(\n",
    "    estimator=knn_scaled,\n",
    "    X=X_train,\n",
    "    ax=ax2,                         # Specify which subplot to use\n",
    "    plot_method='contourf',\n",
    "    response_method='predict',\n",
    "    xlabel=X_train.columns[0],\n",
    "    ylabel=X_train.columns[1],\n",
    "    alpha=0.5,\n",
    "    cmap='RdYlBu_r'\n",
    ")\n",
    "\n",
    "# Add scatter points\n",
    "scatter2 = ax2.scatter(\n",
    "    X_test[\"Income\"],\n",
    "    X_test[\"PSH\"],\n",
    "    c=y_test,\n",
    "    cmap='Paired',\n",
    "    s=20,\n",
    "    edgecolor=\"b\"\n",
    ")\n",
    "\n",
    "# Customize right plot\n",
    "ax2.set_xlim(X_test[\"Income\"].min(), X_test[\"Income\"].max())\n",
    "ax2.set_ylim(X_test[\"PSH\"].min(), X_test[\"PSH\"].max())\n",
    "ax2.legend(scatter2.legend_elements()[0], ['No', 'Yes'], loc='best', title='Classes')\n",
    "acc_scaled = knn_scaled.score(X_test, y_test)\n",
    "ax2.set_title(f\"With Scaling\\nKNN (k=3) | Accuracy: {acc_scaled:.3f}\")\n",
    "\n",
    "# Overall title\n",
    "fig.suptitle(\"Effect of Feature Scaling on KNN Decision Boundaries\", fontsize=14, y=1.02)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print comparison\n",
    "print(f\"Accuracy without scaling: {acc_unscaled:.3f}\")\n",
    "print(f\"Accuracy with scaling: {acc_scaled:.3f}\")\n",
    "print(f\"Improvement: {(acc_scaled - acc_unscaled):.3f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agec-784",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
