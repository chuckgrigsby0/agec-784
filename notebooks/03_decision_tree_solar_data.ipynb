{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a723edc",
   "metadata": {},
   "source": [
    "# Decision Trees for Solar Installation Prediction\n",
    "\n",
    "In this notebook, we will apply the concepts learned about Decision Trees to the solar dataset. You can run this notebook in Google Colab by clicking the link below.\n",
    "\n",
    "Click the badge below to open in Google Colab:\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/chuckgrigsby0/agec-784/blob/main/notebooks/03_decision_tree_solar_data.ipynb)\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Load packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93abc377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b2761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL for raw GitHub content\n",
    "base_url = \"https://raw.githubusercontent.com/chuckgrigsby0/agec-784/main/data/\"\n",
    "\n",
    "# Load solar directly from GitHub URL\n",
    "solar_data = pd.read_csv(base_url + 'solar-data.csv')\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"Number of rows and columns: {solar_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d893571c",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9200ae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the column names\n",
    "# Note that .columns is an attribute of solar_data\n",
    "print(solar_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8171152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first 5 rows of the dataset\n",
    "print(solar_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c4b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute summary statistics, rounded to 4 decimal places \n",
    "# Note: only numeric columns are included\n",
    "np.round(solar_data.describe(), decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c373c6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get counts of number of households that installed solar or not, we can use the value_counts() method\n",
    "solar_data['Install?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408f7b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Install?' to categorical with explicit ordering for consistent outputs\n",
    "solar_data['Install?'] = pd.Categorical(solar_data['Install?'], categories=['No', 'Yes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8353014",
   "metadata": {},
   "source": [
    "## Decision Tree Classification\n",
    "\n",
    "We'll build a classifier to predict whether a household installs solar panels (Yes/No) based on Income and Peak Sun Hours (PSH).\n",
    "\n",
    "### Prepare the data\n",
    "\n",
    "Define features (X) and target variable (y), then split into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c78bae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = solar_data[['Income', 'PSH']]\n",
    "Y = solar_data['Install?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c897454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training (70%) and testing (30%) sets\n",
    "# We evaluate on test data to assess how well the model generalizes to unseen observations\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    Y,\n",
    "    train_size=0.7,\n",
    "    test_size=0.3,\n",
    "    random_state=731\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2thoyj5ln",
   "metadata": {},
   "source": [
    "### Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3001d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(\n",
    "    criterion='gini',              # Measure of split quality for classification\n",
    "    splitter='best',               # Strategy for choosing splits at each node\n",
    "    min_samples_split=5,           # Minimum samples required to split a node\n",
    "    min_samples_leaf=3,            # Minimum samples required in a leaf node\n",
    "    max_features=None,             # Consider all features for splitting\n",
    "    random_state=731               # For reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4962d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_train = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k98oaz649si",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164fe70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_preds = clf_train.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3d890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_accuracy = clf_train.score(X_test, y_test)\n",
    "print(f'Accuracy of Decision Tree Classifier: {clf_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x2t7ndmjp6p",
   "metadata": {},
   "source": [
    "### Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa34f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating on Test Data\n",
    "clf_preds = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': clf_train.predict(X_test)\n",
    "})\n",
    "\n",
    "clf_preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740993c8",
   "metadata": {},
   "source": [
    "### Assessing Model Accuracy\n",
    "\n",
    "Accuracy = 1 - Misclassification Rate\n",
    "\n",
    "The `score()` method measures the model's predictive accuracy. We can also compute accuracy manually comparing actual and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525fb614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All yield the same result\n",
    "\n",
    "print(1 - np.mean(clf_preds['Actual'] != clf_preds['Predicted'])) # Manual calculation of accuracy\n",
    "\n",
    "print(np.mean(clf_preds['Actual'] == clf_preds['Predicted'])) # Manual calculation of accuracy\n",
    "\n",
    "print(clf_train.score(X_test, y_test)) # Using score() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedf04e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix shows counts of correct and incorrect predictions for each class\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(clf_preds['Actual'], clf_preds['Predicted'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b7c35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree depth and number of leaves indicate model complexity\n",
    "print(f'Depth of Decision Tree Classifier: {clf_train.get_depth()}\\n'\n",
    "      f'Number of leaves: {clf_train.get_n_leaves()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qldtqx98c3i",
   "metadata": {},
   "source": [
    "### Examine tree structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0947fe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature and class names for visualization\n",
    "fn = clf_train.feature_names_in_.tolist(); print(f'Predictor names: {fn}')\n",
    "cn = clf_train.classes_.tolist(); print(f'Outcome types: {cn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b12a59",
   "metadata": {},
   "source": [
    "### Visualize the decision tree\n",
    "\n",
    "#### Using `tree.plot_tree()` to visualize the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3014779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "tree.plot_tree(\n",
    "    clf_train,\n",
    "    ax=ax,\n",
    "    feature_names=fn,\n",
    "    class_names=cn,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=12\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/figures/decision_tree_matplotlib.png', \n",
    "            dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97349546",
   "metadata": {},
   "source": [
    "#### Using graphviz to visualize the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b3edca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree = tree.export_graphviz(clf_train, \n",
    "                                 out_file=None,\n",
    "                                 feature_names=fn,  \n",
    "                                 class_names=cn,  \n",
    "                                 filled=True, rounded=True,  \n",
    "                                 special_characters=True)                                  \n",
    "graph = graphviz.Source(plot_tree, \n",
    "                        filename=\"decision_tree_solar_data\",\n",
    "                        directory='output/figures/', \n",
    "                        format='png')  \n",
    "\n",
    "graph.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uj87lxj0ns",
   "metadata": {},
   "source": [
    "## Decision Tree Regression\n",
    "\n",
    "Decision tree regression predicts continuous values (Profit) rather than categories. We'll use the same features but different target variable.\n",
    "\n",
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5ad489",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = solar_data[['Income', 'PSH']]\n",
    "Y = solar_data['Profit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0136c066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same train/test split process as classification, but with Profit as the target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    Y,\n",
    "    train_size=0.7,\n",
    "    test_size=0.3,\n",
    "    random_state=731\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m3ioz3nm4cb",
   "metadata": {},
   "source": [
    "### Train the regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed381e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_regr = tree.DecisionTreeRegressor(\n",
    "    criterion='squared_error',     # MSE criterion for regression (not gini)\n",
    "    splitter='best',               # Strategy for choosing splits at each node\n",
    "    min_samples_split=5,           # Minimum samples required to split a node\n",
    "    min_samples_leaf=5,            # Minimum samples in a leaf (higher than classifier)\n",
    "    max_depth=None,                # No maximum depth constraint\n",
    "    max_features=None,             # Consider all features for splitting\n",
    "    random_state=731               # For reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd74501",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_regr = tree_regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ldo9up4zjw",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e42876",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_regr_preds = tree_regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7b29c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating on Test Data\n",
    "tree_regr_preds = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': tree_regr.predict(X_test)\n",
    "})\n",
    "\n",
    "tree_regr_preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbubgyhesyn",
   "metadata": {},
   "source": [
    "### Evaluate model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c46e3e7",
   "metadata": {},
   "source": [
    "### Assessing Model Accuracy\n",
    "\n",
    "$R^2 = 1 - \\frac{\\sum_{i}((y_{i} - \\hat{y}_{i})^{2})}{\\sum_{i}((y_{i} - \\bar{y})^{2})}$\n",
    "\n",
    "RÂ² ranges from 0 to 1, where 1 indicates perfect predictions and 0 means the model performs no better than predicting the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a919387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All yield the same result\n",
    "numerator = np.sum((tree_regr_preds['Actual'] - tree_regr_preds['Predicted']) ** 2)\n",
    "denominator = np.sum((tree_regr_preds['Actual'] - np.mean(tree_regr_preds['Actual'])) ** 2)\n",
    "\n",
    "print(1 - numerator / denominator) # Manual calculation of R^2\n",
    "\n",
    "print(tree_regr.score(X_test, y_test)) # Using score() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcdfdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Depth of Decision Tree: {tree_regr.get_depth()}\\n'\n",
    "      f'Number of leaves: {tree_regr.get_n_leaves()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087mtfpg1bn8",
   "metadata": {},
   "source": [
    "### Examine tree structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96998ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = tree_regr.feature_names_in_.tolist(); print(f'Predictor names: {fn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2101bf5d",
   "metadata": {},
   "source": [
    "### Visualize the regression tree\n",
    "\n",
    "#### Using `tree.plot_tree()` to visualize the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3045bc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 10))\n",
    "tree.plot_tree(\n",
    "    tree_regr,\n",
    "    ax=ax,\n",
    "    feature_names=fn,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=12\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/figures/reg_decision_tree_matplotlib.png', \n",
    "            dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aba44cd",
   "metadata": {},
   "source": [
    "### Advanced: Computing Feature Importance\n",
    "\n",
    "**Feature Importance** quantifies how much each feature contributed to the model's predictions. \n",
    "\n",
    "**How it's calculated**: For each feature, the model sums the variance reduction (decrease in MSE) at every split using that feature, weighted by the proportion of samples affected by each split. Values are normalized to sum to 1.0.\n",
    "\n",
    "**How to interpret**: Features with higher importance are more influential for predictions. A feature with importance of 0.30 contributed roughly 30% of the total predictive power. However, low importance doesn't necessarily mean a feature is unimportant, as it may be correlated with other features or relevant only for specific subgroups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fdc575",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.Series(\n",
    "    tree_regr.feature_importances_,\n",
    "    index=X_train.columns\n",
    ").sort_values(ascending=False)\n",
    "print(f\"Feature importances:\\n{np.round(importances, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d85025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance_seaborn(model, feature_names, top_n=10, figsize=(10, 6)):\n",
    "    \"\"\"\n",
    "    Create a seaborn-styled feature importance plot.\n",
    "    \"\"\"\n",
    "    # Get importances\n",
    "    importances = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False).head(top_n)\n",
    "    \n",
    "    # Set style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_palette(\"husl\")\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Create barplot\n",
    "    sns.barplot(\n",
    "        data=importances,\n",
    "        y='feature',\n",
    "        x='importance',\n",
    "        hue='feature',\n",
    "        ax=ax,\n",
    "        palette='viridis'\n",
    "    )\n",
    "    \n",
    "    # Styling\n",
    "    ax.set_xlabel('Importance', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Feature', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Top Feature Importances', fontsize=14, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, v in enumerate(importances['importance']):\n",
    "        ax.text(v, i, f' {v:.3f}', va='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    sns.reset_defaults()  # Reset to avoid affecting other plots\n",
    "    return fig, ax\n",
    "\n",
    "# Usage\n",
    "fig, ax = plot_feature_importance_seaborn(tree_regr, X_train.columns, top_n=10)\n",
    "plt.savefig('output/figures/feature_importance_seaborn.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agec-784",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
