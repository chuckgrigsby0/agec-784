{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYK9UY0UiIjh"
      },
      "source": [
        "## Importing Data from Google Drive to Colab Environment\n",
        "\n",
        "This notebook illustrates how to access data in your Google Drive account from Colab, import the data, and do some preliminary data cleaning before using it in analysis.\n",
        "\n",
        "Click the badge below to open in Google Colab:\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/chuckgrigsby0/agec-784/blob/main/notebooks/01_load_data_into_colab_csv.ipynb)\n",
        "\n",
        "The following code block mounts your Google Drive account, giving you access to your files saved in `MyDrive`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZowZwWeHkpP"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rjqybb0tjK40"
      },
      "source": [
        "Next we will import `pandas` and `numpy`. Note that this assumes you have your data saved in the `Data` folder within `MyDrive`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zadwY_NHzt1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('drive/MyDrive/Data/corn_production_by_state_2022_2017.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMSpz9jEjaxb"
      },
      "source": [
        "The next lines of code show several useful attributes and methods to remember for better understanding the properties of your data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kn2FjHzNIlvy"
      },
      "outputs": [],
      "source": [
        "# Column names\n",
        "print(f\"Column names: {df.columns.to_list()}\")\n",
        "print(f\"First five rows:\\n{df.head()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcR7zgathbRg"
      },
      "source": [
        "### Clean `Value` Column\n",
        "\n",
        "In most cases, when you download USDA NASS data, the `Value` column containing our variable of interest will need to be cleaned before we can use it for analyses. The following code uses regular expressions [(regex)](https://en.wikipedia.org/wiki/Regular_expression) to remove any row containing a \"(D)\", a flag indicating the value is withheld to avoid disclosing individual farm data, and \"(Z)\" indicating when less than half of the unit is shown.\n",
        "\n",
        "We also need to convert the `Value` column to a `float` data type, as it is formatted as a string when we initially import it.\n",
        "\n",
        "The following line of code creates a boolean (True/False) vector that indicates when `Value` contains \"(D)\" or \"(Z)\"."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Value'].astype(str).str.contains(r'\\((?:D|Z)\\)', regex=True, na=False).any()"
      ],
      "metadata": {
        "id": "gYLVHdO6h1WX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7ePlj3FhbRh"
      },
      "outputs": [],
      "source": [
        "mask = df['Value'].astype(str).str.contains(r'^\\s*\\((?:D|Z)\\)\\s*$', regex=True, na=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RClywt_UhbRh"
      },
      "source": [
        "Because we want to keep rows *not* containing \"(D)\" or \"(Z)\", we use the `~` operator to invert the boolean mask. This converts `True` to `False` and `False` to `True`, so rows that matched the pattern (originally `True`) become `False` and are filtered out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQE-QfhDhbRh"
      },
      "outputs": [],
      "source": [
        "df = df[~mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLC7XNTWhbRh"
      },
      "outputs": [],
      "source": [
        "# Verify that '(D)' and '(Z)' values have been removed\n",
        "df['Value'].astype(str).str.contains(r'\\((?:D|Z)\\)', regex=True, na=False).any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsXBHPQ7hbRi"
      },
      "outputs": [],
      "source": [
        "# Check the data type of the 'Value' column\n",
        "df['Value'].dtype # 'O' indicates string variable type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHZV1DwIhbRi"
      },
      "source": [
        "If the `Value` column also contains `,` we also need to remove these before converting `Value` to a numeric variable type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ai9AQk3hbRi"
      },
      "outputs": [],
      "source": [
        "# Remove ',' from `Value` column\n",
        "df['Value'] = df['Value'].astype(str).str.replace(',', '', regex=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR1Kn547hbRi"
      },
      "source": [
        "Lastly, we need to convert `Value` from a string variable type to a numeric variable type. We use `pandas` `to_numeric()` function for this. We also drop any `NA` values to ensure the `Value` column is clean for analyses.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9zlyPe4hbRi"
      },
      "outputs": [],
      "source": [
        "# Convert to numeric\n",
        "df['Value'] = pd.to_numeric(df['Value'], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for NAs\n",
        "df['Value'].isna().sum()\n",
        "# df.dropna(subset=['Value'], inplace=True) # Drop NAs if needed"
      ],
      "metadata": {
        "id": "Y9y108Rpi37x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4KkS-zxhbRi"
      },
      "outputs": [],
      "source": [
        "# Show all numerical variables with 2 decimal places, no scientific notation\n",
        "pd.set_option('display.float_format', lambda x: f'{x:.2f}')\n",
        "df['Value'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BvZtxo0L2R1"
      },
      "outputs": [],
      "source": [
        "# Unique years data\n",
        "df['Year'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3YBTSM2OUWv"
      },
      "outputs": [],
      "source": [
        "# Unique variable types\n",
        "df['Data Item'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "XRliC5-FPm13"
      },
      "outputs": [],
      "source": [
        "# Unique states\n",
        "df['State'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRFZ4QX2Rssu"
      },
      "outputs": [],
      "source": [
        "# You can also combine text using \"\" and wrapping values inside {}\n",
        "# for more descriptive output.\n",
        "print(f\"Unique counties in data include: {df['State'].unique()}\")\n",
        "print(f\"Unique years in data include: {df['Year'].unique()}\")\n",
        "print(f\"Unique cattle types in data include: {df['Data Item'].unique()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4mD_jxgnq5I"
      },
      "outputs": [],
      "source": [
        "df_filter = df[df['Year'] == 2022]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8RVutXpn8DQ"
      },
      "outputs": [],
      "source": [
        "df_filter['Year'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOO4drqIPtQd"
      },
      "outputs": [],
      "source": [
        "# Grouped statistics.\n",
        "desc_stats = df.groupby(['State', 'Data Item']).agg({'Value': ['mean', 'std']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1GYGHisohwi"
      },
      "outputs": [],
      "source": [
        "print(desc_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abvyJ_SjRqcR"
      },
      "outputs": [],
      "source": [
        "filename = 'desc_stats_cattle_by_county_and_type.csv'\n",
        "desc_stats.to_csv(f\"/content/drive/MyDrive/Data/{filename}\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}